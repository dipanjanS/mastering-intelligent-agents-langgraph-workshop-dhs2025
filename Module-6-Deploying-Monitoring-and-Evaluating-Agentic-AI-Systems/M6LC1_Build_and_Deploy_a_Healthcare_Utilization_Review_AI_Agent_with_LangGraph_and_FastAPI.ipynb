{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/mastering-intelligent-agents-langgraph-workshop-dhs2025/blob/main/Module-6-Deploying-Monitoring-and-Evaluating-Agentic-AI-Systems/M6LC1_Build_and_Deploy_a_Healthcare_Utilization_Review_AI_Agent_with_LangGraph_and_FastAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zM0hebRaut5"
      },
      "source": [
        "# Build and Deploy a Healthcare Utilization Review Agent with LangGraph & FastAPI\n",
        "\n",
        "This notebook walks you through building and running a **Healthcare Utilization Review** agent using **LangGraph** and exposing it via a **FastAPI** web service. You‚Äôll deploy the API inside the notebook (Uvicorn in a background thread) and call it from the same notebook with `requests`.\n",
        "\n",
        "![](https://i.imgur.com/ThwlmGc.png)\n",
        "\n",
        "**What you‚Äôll get**\n",
        "- A LangGraph agent (System Prompt + LLM) that calls domain tools:\n",
        "  - `fetch_patient_record`, `match_guideline`, `check_guideline_validity`, `recommend_care_plan`\n",
        "- A FastAPI service with health & patient endpoints plus a review endpoint (JSON), and a streaming review endpoint\n",
        "- In-memory demo data: `patient_records`, `medical_guidelines`, `care_recommendations`\n",
        "- Client cells that hit the API with `requests.get(...)` and `requests.post(...)`\n",
        "\n",
        "**Endpoints**\n",
        "- `GET /health` ‚Äì service status\n",
        "- `GET /patients` ‚Äì list patient IDs\n",
        "- `GET /patient/{id}` ‚Äì patient details\n",
        "- `POST /review/invoke` ‚Äì run a full review and return JSON\n",
        "- `POST /review/stream` ‚Äì stream review progress and tokens (SSE), if enabled\n",
        "\n",
        "**Review JSON output (non-streaming)**\n",
        "- `patient_id`\n",
        "- `decision` (`APPROVED` or `NEEDS REVIEW`)\n",
        "- `reasoning`\n",
        "- `care_recommendation`\n",
        "- `processing_time` (seconds)\n",
        "\n",
        "**Architecture (at a glance)**\n",
        "Client (`requests`) ‚Üí **FastAPI** ‚Üí **Agent (System Prompt + LLM)** ‚Üí **Tools** ‚Üí **In-memory Data** ‚Üí API Response\n",
        "\n",
        "> Tip: The API is started in a background thread so you can test endpoints from the same notebook. Set `OPENAI_API_KEY` before running.\n"
      ],
      "id": "4zM0hebRaut5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpRChrRuaut6"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Install the required packages for the agent, tools, and API. Run this **once** (rerun if the runtime resets).\n"
      ],
      "id": "wpRChrRuaut6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi==0.116.1 uvicorn==0.35.0 langchain==0.3.27 langchain-community==0.3.27 langchain-openai==0.3.30 langgraph==0.6.5 --quiet"
      ],
      "id": "install"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7ytgT0Taut7"
      },
      "source": [
        "## Configure API Keys & Environment\n",
        "\n",
        "Set your OpenAI API key for `ChatOpenAI` and set it in the environment"
      ],
      "id": "j7ytgT0Taut7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apikey"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# OpenAI API Key (for chat & embeddings)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key (https://platform.openai.com/account/api-keys):\\n\")\n"
      ],
      "id": "apikey"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE0C-1M7aut8"
      },
      "source": [
        "## Imports"
      ],
      "id": "dE0C-1M7aut8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "import threading\n",
        "import requests\n",
        "from typing import Annotated, List, Dict, Any, AsyncGenerator\n",
        "from typing_extensions import TypedDict\n",
        "from contextlib import asynccontextmanager\n",
        "\n",
        "# FastAPI imports\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import StreamingResponse\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "# LangGraph and LangChain imports\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage"
      ],
      "id": "imports"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EHVBxMNaut8"
      },
      "source": [
        "## Sample Data (Guidelines, Care Plans, Patient Records)\n",
        "\n",
        "This notebook uses **in-memory** Python lists to keep the demo self-contained.  \n",
        "You can later swap these out for a database or API without changing the agent‚Äôs logic.\n",
        "\n",
        "### What‚Äôs included\n",
        "- **`medical_guidelines`** ‚Äî evidence-style rules the agent can match against.\n",
        "  - Fields: `procedure`, `diagnosis`, `required_symptoms` (list), `notes` (free text).\n",
        "  - Example:\n",
        "    ```python\n",
        "    {\n",
        "      \"procedure\": \"CT Abdomen\",\n",
        "      \"diagnosis\": \"Suspected Appendicitis\",\n",
        "      \"required_symptoms\": [\"abdominal pain\", \"nausea\", \"RLQ tenderness\"],\n",
        "      \"notes\": \"CT imaging justified if appendicitis is unclear.\"\n",
        "    }\n",
        "    ```\n",
        "- **`care_recommendations`** ‚Äî next-step suggestions keyed by diagnosis.\n",
        "  - Fields: `diagnosis`, `next_step`.\n",
        "  - Example:\n",
        "    ```python\n",
        "    {\n",
        "      \"diagnosis\": \"Suspected Appendicitis\",\n",
        "      \"next_step\": \"Do CT to confirm and refer for surgery if positive.\"\n",
        "    }\n",
        "    ```\n",
        "- **`patient_records`** ‚Äî small synthetic chart notes for testing.\n",
        "  - Fields: `patient_id`, `age`, `sex`, `symptoms` (list), `diagnosis`, `procedure`, `notes`.\n",
        "  - Example:\n",
        "    ```python\n",
        "    {\n",
        "      \"patient_id\": \"P101\",\n",
        "      \"age\": 38,\n",
        "      \"sex\": \"Male\",\n",
        "      \"symptoms\": [\"abdominal pain\", \"nausea\"],\n",
        "      \"diagnosis\": \"Possible early appendicitis\",\n",
        "      \"procedure\": \"CT Abdomen\",\n",
        "      \"notes\": \"Mild abdominal pain and nausea but no localized tenderness or rebound noted.\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "### How the agent uses these\n",
        "- **Guideline matching**: `procedure` + `diagnosis` ‚Üí pick the closest entry in `medical_guidelines`.\n",
        "- **Validity check**: compare `patient_records[*].symptoms` vs. `required_symptoms` and read `notes`.\n",
        "- **Care plan**: map `diagnosis` ‚Üí `care_recommendations[*].next_step`."
      ],
      "id": "3EHVBxMNaut8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data"
      },
      "outputs": [],
      "source": [
        "medical_guidelines = [\n",
        "    {\"procedure\": \"MRI Brain\", \"diagnosis\": \"Migraine\", \"required_symptoms\": [\"headache\", \"nausea\"],\n",
        "     \"notes\": \"MRI not recommended unless neurological deficits or red flags present.\"},\n",
        "    {\"procedure\": \"CT Chest\", \"diagnosis\": \"Suspected Pulmonary Embolism\", \"required_symptoms\": [\"chest pain\", \"shortness of breath\", \"tachycardia\"],\n",
        "     \"notes\": \"CTPA appropriate for high probability PE cases with positive D-dimer.\"},\n",
        "    {\"procedure\": \"MRI Lumbar Spine\", \"diagnosis\": \"Chronic Low Back Pain\", \"required_symptoms\": [\"back pain > 6 weeks\", \"neurological deficit\"],\n",
        "     \"notes\": \"MRI only if pain persists despite conservative therapy and neuro signs are present.\"},\n",
        "    {\"procedure\": \"CT Chest\", \"diagnosis\": \"Community-Acquired Pneumonia\", \"required_symptoms\": [\"fever\", \"cough\"],\n",
        "     \"notes\": \"CT Chest reserved for inconclusive X-rays or immunocompromised patients.\"},\n",
        "    {\"procedure\": \"CT Abdomen\", \"diagnosis\": \"Suspected Appendicitis\", \"required_symptoms\": [\"abdominal pain\", \"nausea\", \"RLQ tenderness\"],\n",
        "     \"notes\": \"CT imaging justified if appendicitis is unclear.\"}\n",
        "]\n",
        "\n",
        "care_recommendations = [\n",
        "    {\"diagnosis\": \"Migraine\", \"next_step\": \"Start migraine treatment; imaging not necessary unless red flags appear.\"},\n",
        "    {\"diagnosis\": \"Suspected Pulmonary Embolism\", \"next_step\": \"Begin anticoagulation and confirm with CTPA.\"},\n",
        "    {\"diagnosis\": \"Chronic Low Back Pain\", \"next_step\": \"Refer to physiotherapy; MRI only if neuro symptoms persist.\"},\n",
        "    {\"diagnosis\": \"Community-Acquired Pneumonia\", \"next_step\": \"Start empirical antibiotics; reserve CT for poor responders.\"},\n",
        "    {\"diagnosis\": \"Suspected Appendicitis\", \"next_step\": \"Do CT to confirm and refer for surgery if positive.\"}\n",
        "]\n",
        "\n",
        "patient_records = [\n",
        "    {\"patient_id\": \"P101\", \"age\": 38, \"sex\": \"Male\", \"symptoms\": [\"abdominal pain\", \"nausea\"],\n",
        "     \"diagnosis\": \"Possible early appendicitis\", \"procedure\": \"CT Abdomen\",\n",
        "     \"notes\": \"Mild abdominal pain and nausea but no localized tenderness or rebound noted.\"},\n",
        "    {\"patient_id\": \"P102\", \"age\": 65, \"sex\": \"Female\", \"symptoms\": [\"chest pain\", \"shortness of breath\", \"tachycardia\"],\n",
        "     \"diagnosis\": \"Clinical suspicion of PE\", \"procedure\": \"CT Chest\",\n",
        "     \"notes\": \"Wells score high probability; D-dimer positive.\"},\n",
        "    {\"patient_id\": \"P103\", \"age\": 30, \"sex\": \"Female\", \"symptoms\": [\"recurrent headache\"],\n",
        "     \"diagnosis\": \"Classic migraine presentation\", \"procedure\": \"MRI Brain\",\n",
        "     \"notes\": \"No neuro signs or red flags. Typical migraine pattern.\"},\n",
        "    {\"patient_id\": \"P104\", \"age\": 45, \"sex\": \"Male\", \"symptoms\": [\"back pain > 6 weeks\", \"neurological deficit\"],\n",
        "     \"diagnosis\": \"Chronic Low Back Pain\", \"procedure\": \"MRI Lumbar Spine\",\n",
        "     \"notes\": \"Persistent low back pain with left leg numbness; unresponsive to physiotherapy.\"},\n",
        "    {\"patient_id\": \"P105\", \"age\": 70, \"sex\": \"Female\", \"symptoms\": [\"fever\", \"cough\"],\n",
        "     \"diagnosis\": \"Community-Acquired Pneumonia\", \"procedure\": \"CT Chest\",\n",
        "     \"notes\": \"Initial chest X-ray inconclusive; patient is immunocompromised with underlying COPD.\"}\n",
        "]\n"
      ],
      "id": "data"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tShL2UU1aut8"
      },
      "source": [
        "## Tools for the Utilization Review Agent\n",
        "\n",
        "These are **LangChain tools** (decorated with `@tool`) that the agent can call during a review.  \n",
        "They encapsulate domain logic and return **small, structured dicts** the agent can reason over.\n",
        "\n",
        "### Summary of tools\n",
        "\n",
        "| Tool | Purpose | Inputs | Output keys |\n",
        "|---|---|---|---|\n",
        "| `fetch_patient_record` | Retrieve and summarize a patient chart from in-memory data | `patient_id: str` | `patient_summary` _(str)_, or `error` |\n",
        "| `match_guideline` | Pick the closest clinical guideline for a (procedure, diagnosis) pair using the LLM | `procedure: str`, `diagnosis: str` | `matched_guideline` _(str)_ |\n",
        "| `check_guideline_validity` | Validate whether patient symptoms/notes meet the guideline‚Äôs criteria | `symptoms: list[str]`, `required_symptoms: list[str]`, `notes: str` | `validity_result` _(str)_ |\n",
        "| `recommend_care_plan` | Suggest next steps for the given diagnosis | `diagnosis: str` | `recommendation` _(str)_ |\n",
        "\n",
        "> All LLM-backed tools use `ChatOpenAI` (temperature = 0, streaming enabled in code) and return **concise textual justifications** under a single key.\n",
        "\n",
        "### Typical call order used by the agent\n",
        "1. `fetch_patient_record(patient_id)` ‚Üí summarize context  \n",
        "2. `match_guideline(procedure, diagnosis)` ‚Üí find best-fit rule  \n",
        "3. `check_guideline_validity(symptoms, required_symptoms, notes)` ‚Üí approve vs. needs review  \n",
        "4. `recommend_care_plan(diagnosis)` ‚Üí action steps / alternatives\n",
        "\n",
        "### Example outputs (shape)\n",
        "```json\n",
        "// fetch_patient_record\n",
        "{ \"patient_summary\": \"Patient ID: P102\\nAge: 65, Sex: Female\\nReported Symptoms: chest pain, shortness of breath, tachycardia\\nPreliminary Diagnosis: Clinical suspicion of PE\\nRequested Procedure: CT Chest\\nClinical Notes: Wells score high probability; D-dimer positive.\" }\n",
        "\n",
        "// match_guideline\n",
        "{ \"matched_guideline\": \"CTPA is appropriate for high-probability PE with positive D-dimer. Required symptoms: chest pain, shortness of breath, tachycardia. Caveats: ensure renal function adequate for contrast.\" }\n",
        "\n",
        "// check_guideline_validity\n",
        "{ \"validity_result\": \"Criteria met: symptoms align and notes indicate high probability (Wells) with positive D-dimer. Imaging is medically necessary.\" }\n",
        "\n",
        "// recommend_care_plan\n",
        "{ \"recommendation\": \"Begin anticoagulation and confirm with CTPA; monitor hemodynamics; consider risk stratification.\" }\n"
      ],
      "id": "tShL2UU1aut8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tools"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def fetch_patient_record(patient_id: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fetches and summarizes a patient record based on the given patient ID.\n",
        "    Returns a short summary string.\n",
        "    \"\"\"\n",
        "    for record in patient_records:\n",
        "        if record[\"patient_id\"] == patient_id:\n",
        "            summary = (\n",
        "                f\"Patient ID: {record['patient_id']}\\n\"\n",
        "                f\"Age: {record['age']}, Sex: {record['sex']}\\n\"\n",
        "                f\"Reported Symptoms: {', '.join(record['symptoms'])}\\n\"\n",
        "                f\"Preliminary Diagnosis: {record['diagnosis']}\\n\"\n",
        "                f\"Requested Procedure: {record['procedure']}\\n\"\n",
        "                f\"Clinical Notes: {record['notes']}\"\n",
        "            )\n",
        "            return {\"patient_summary\": summary}\n",
        "    return {\"error\": \"Patient record not found.\"}\n",
        "\n",
        "@tool\n",
        "def match_guideline(procedure: str, diagnosis: str) -> dict:\n",
        "    \"\"\"Match a given procedure and diagnosis to the most relevant clinical guideline.\"\"\"\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
        "    context = \"\\n\".join([\n",
        "        f\"{i+1}. Procedure: {g['procedure']}, Diagnosis: {g['diagnosis']}, Required Symptoms: {g['required_symptoms']}, Notes: {g['notes']}\"\n",
        "        for i, g in enumerate(medical_guidelines)])\n",
        "\n",
        "    prompt = f\"\"\"You are a clinical reviewer assessing whether a requested medical procedure aligns with existing evidence-based guidelines.\n",
        "\n",
        "Instructions:\n",
        "- Analyze the patient's procedure and diagnosis.\n",
        "- Compare against the list of provided clinical guidelines.\n",
        "- Select the guideline that best fits the case by reasoning on the common matches considering procedure and diagnosis.\n",
        "- If none match, respond: \"No appropriate guideline found for this case.\"\n",
        "- If a match is found, summarize the matching guideline clearly including any required symptoms or caveats.\n",
        "\n",
        "Patient Case:\n",
        "- Procedure: {procedure}\n",
        "- Diagnosis: {diagnosis}\n",
        "\n",
        "Available Guidelines:\n",
        "{context}\n",
        "\"\"\"\n",
        "    result = llm.invoke(prompt).content\n",
        "    return {\"matched_guideline\": result}\n",
        "\n",
        "@tool\n",
        "def check_guideline_validity(symptoms: list, required_symptoms: list, notes: str) -> dict:\n",
        "    \"\"\"Determine whether the patient's symptoms and notes satisfy the guideline criteria.\"\"\"\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
        "    prompt = f\"\"\"You are validating a medical procedure request based on documented symptoms and clinical context.\n",
        "\n",
        "Instructions:\n",
        "- Assess whether the patient's symptoms and notes fulfill the required guideline criteria.\n",
        "- Consider nuances or indirect references (e.g. \"long flight\" implies immobility).\n",
        "- Provide a reasoned judgment if the procedure is medically necessary.\n",
        "- If it does not qualify, explain exactly which criteria are unmet.\n",
        "\n",
        "Input:\n",
        "- Patient Symptoms: {symptoms}\n",
        "- Required Symptoms from Guideline: {required_symptoms}\n",
        "- Clinical Notes: {notes}\n",
        "\"\"\"\n",
        "    result = llm.invoke(prompt).content\n",
        "    return {\"validity_result\": result}\n",
        "\n",
        "@tool\n",
        "def recommend_care_plan(diagnosis: str) -> dict:\n",
        "    \"\"\"Recommend a follow-up care plan based on a given diagnosis.\"\"\"\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
        "    options = \"\\n\".join([\n",
        "        f\"{i+1}. Diagnosis: {c['diagnosis']}, Recommendation: {c['next_step']}\"\n",
        "        for i, c in enumerate(care_recommendations)])\n",
        "\n",
        "    prompt = f\"\"\"You are a clinical support assistant suggesting appropriate next steps for a given medical diagnosis.\n",
        "\n",
        "Instructions:\n",
        "- Analyze the given diagnosis.\n",
        "- Choose the closest match from the list of known recommendations.\n",
        "- Explain why the match is appropriate.\n",
        "- If no suitable recommendation is found, return: \"No care recommendation found for this diagnosis.\"\n",
        "\n",
        "Diagnosis Provided:\n",
        "{diagnosis}\n",
        "\n",
        "Available Recommendations:\n",
        "{options}\n",
        "\"\"\"\n",
        "    result = llm.invoke(prompt).content\n",
        "    return {\"recommendation\": result}\n"
      ],
      "id": "tools"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bicopt7Oaut9"
      },
      "source": [
        "## LangGraph Agent Setup\n",
        "\n",
        "This section wires up a **tool-using ReAct agent** with LangGraph. The agent reads a system prompt, plans calls to our tools, and produces a strict final summary (Decision, Reasoning, Care).\n",
        "\n",
        "### Components\n",
        "- **System Prompt** ‚Äî defines the reviewer role and enforces the final **bullet-format** output.\n",
        "- **State** ‚Äî a `TypedDict` with a `messages` array aggregated by `add_messages`.\n",
        "- **LLM (ChatOpenAI)** ‚Äî initialized with `streaming=True` and **bound** to tools so it can call them.\n",
        "- **Graph** ‚Äî `StateGraph` with:\n",
        "  - `agent` node: decides what to do next (call tools or finish).\n",
        "  - `tools` node: executes tool calls (`ToolNode`).\n",
        "  - Edges: `START ‚Üí agent ‚Üí (tools?) ‚Üí agent ‚Üí END` via `tools_condition`.\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/s9hSJ6l.png)"
      ],
      "id": "Bicopt7Oaut9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agent"
      },
      "outputs": [],
      "source": [
        "AGENT_SYS_PROMPT = \"\"\"\n",
        "You are a senior medical review assistant responsible for evaluating healthcare procedure requests.\n",
        "\n",
        "You must call relevant tools to do the following:\n",
        "1. Retrieve the full patient record using the patient ID.\n",
        "2. Match the requested procedure and diagnosis to clinical guidelines.\n",
        "3. Validate the match by comparing the patient's symptoms and notes to the guideline's requirements.\n",
        "4. Recommend the appropriate next steps based on the diagnosis.\n",
        "5. Output a final summary based on the guidelines given below.\n",
        "\n",
        "Analyze all the results from the tool calls before making the final decision\n",
        "\n",
        "Your final response should ONLY include the following bullets in the exact format specified:\n",
        "\n",
        "- Final Decision: [APPROVED/NEEDS REVIEW]\n",
        "- Decision Reasoning: [What criteria matched or did not match]\n",
        "- Care recommendation or alternative steps: [care plan steps to take or alternative steps if it needs review]\n",
        "\n",
        "Do NOT add any other extra content in the final response\n",
        "\"\"\"\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
        "tools = [fetch_patient_record, match_guideline, check_guideline_validity, recommend_care_plan]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def tool_calling_llm(state: State) -> State:\n",
        "    \"\"\"Handle reasoning and planning using the LLM (tool-call capable).\"\"\"\n",
        "    current_state = state[\"messages\"]\n",
        "    state_with_instructions = [AGENT_SYS_PROMPT] + current_state\n",
        "    response = [llm_with_tools.invoke(state_with_instructions)]\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def create_utilization_review_agent():\n",
        "    builder = StateGraph(State)\n",
        "    builder.add_node(\"agent\", tool_calling_llm)\n",
        "    builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "    builder.add_edge(START, \"agent\")\n",
        "    builder.add_conditional_edges(\"agent\", tools_condition, [\"tools\", END])\n",
        "    builder.add_edge(\"tools\", \"agent\")\n",
        "    return builder.compile()\n",
        "\n",
        "utilization_review_agent = create_utilization_review_agent()"
      ],
      "id": "agent"
    },
    {
      "cell_type": "code",
      "source": [
        "utilization_review_agent"
      ],
      "metadata": {
        "id": "N8iDy1tC_AOF"
      },
      "id": "N8iDy1tC_AOF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Agent Locally Directly\n",
        "\n",
        "Use the compiled LangGraph agent **without** the API to run some utilization reviews"
      ],
      "metadata": {
        "id": "hn8c65jn_DLk"
      },
      "id": "hn8c65jn_DLk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Direct Invocation"
      ],
      "metadata": {
        "id": "QmxGkKLZ_jUW"
      },
      "id": "QmxGkKLZ_jUW"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Review patient P101 for procedure justification.\"\n",
        "result = utilization_review_agent.invoke({\"messages\": [(\"user\", prompt)]},\n",
        "                                         {\"recursion_limit\": 25})"
      ],
      "metadata": {
        "id": "-NodOKGb_Qqn"
      },
      "id": "-NodOKGb_Qqn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "83cTPo9l_Z2G"
      },
      "id": "83cTPo9l_Z2G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Live Streaming"
      ],
      "metadata": {
        "id": "nxk_lTUZ_nQx"
      },
      "id": "nxk_lTUZ_nQx"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Review patient P101 for procedure justification.\"\n",
        "for event in utilization_review_agent.stream({\"messages\": [(\"user\", prompt)]},\n",
        "                                             {\"recursion_limit\": 25},\n",
        "                                             stream_mode='values'):\n",
        "    event['messages'][-1].pretty_print()"
      ],
      "metadata": {
        "id": "Vr3HJrml_pw3"
      },
      "id": "Vr3HJrml_pw3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEGWeq6Haut9"
      },
      "source": [
        "## Wrap AI Agent in a FastAPI Web Service (API)\n",
        "\n",
        "This cell initializes the **FastAPI** application and its lifecycle:\n",
        "\n",
        "- **Lifespan manager** (`@asynccontextmanager`) runs once on startup and once on shutdown, printing clear logs so you know when the API is ready and when it stops. This replaces older `@app.on_event(\"startup\"/\"shutdown\")` patterns.\n",
        "- **App metadata** (`title`, `description`, `version`) populates the interactive docs (`/docs`) and helps with observability.\n",
        "- **CORS middleware** is enabled with permissive settings (`*`) so your **notebook client** (and other origins) can call the API without browser/CORS issues.\n",
        "\n",
        "> This cell only **creates and configures** the app; it does **not** start the server.\n",
        "\n",
        "Routes are added in later cells, and the server is launched via Uvicorn in a background thread so you can test endpoints from the same notebook.\n"
      ],
      "id": "kEGWeq6Haut9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fastapi-app"
      },
      "outputs": [],
      "source": [
        "@asynccontextmanager\n",
        "async def lifespan(app: FastAPI):\n",
        "    # Startup\n",
        "    print(\"Healthcare Utilization Review AI Agent API Starting...\")\n",
        "    print(\"AI Agent API initialized and ready\")\n",
        "    yield\n",
        "    # Shutdown\n",
        "    print(\"Healthcare Utilization Review AI Agent API Shutting down...\")\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Healthcare Utilization Review AI Agent API\",\n",
        "    description=\"AI-powered utilization review system\",\n",
        "    version=\"1.0.0\",\n",
        "    lifespan=lifespan,\n",
        ")\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n"
      ],
      "id": "fastapi-app"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BnnUk0faut-"
      },
      "source": [
        "## Define Request/Response Schema and API Endpoints\n",
        "\n",
        "This cell declares the **Pydantic models** used for validation/typing and wires up the **HTTP routes** that your client calls.\n",
        "\n",
        "### Schemas\n",
        "- **`ReviewRequest`** ‚Äî body for non-streaming review  \n",
        "  - `patient_id: str`\n",
        "- **`StreamingReviewRequest`** ‚Äî body for streaming review  \n",
        "  - `patient_id: str` ¬∑ `include_tool_calls: bool = True`\n",
        "- **`ReviewResponse`** ‚Äî final structured review output (non-streaming)  \n",
        "  - `patient_id, decision, reasoning, care_recommendation, processing_time: float`\n",
        "- **`HealthResponse`** ‚Äî health check payload  \n",
        "  - `status, timestamp, version`\n",
        "\n",
        "### Endpoints\n",
        "- **GET `/health`** ‚Üí returns `HealthResponse` (service heartbeat).\n",
        "- **GET `/patients`** ‚Üí `{ patients: [ids], count }` from in-memory data.\n",
        "- **GET `/patient/{patient_id}`** ‚Üí full record for a specific patient; `404` if not found.\n",
        "- **POST `/review/invoke`** ‚Üí runs the agent to completion and returns a single `ReviewResponse`.  \n",
        "  - Internally: builds a prompt ‚Üí `agent.invoke(...)` ‚Üí parses the strict 3-bullet output into `decision`, `reasoning`, `care_recommendation`, and computes `processing_time`.\n",
        "- **POST `/review/stream`** ‚Üí streams the live review as **SSE** frames (one line per event).  \n",
        "  - Emits JSON lines prefixed with `data: ` and ends with `data: [DONE]`.\n",
        "  - Event types you‚Äôll see:\n",
        "    - `{\"status\": \"starting\", ...}` ‚Äî initial notice.\n",
        "    - `{\"type\": \"tool_start\", \"tool\": \"<name>\", \"message\": \"...\"}` ‚Äî a tool began.\n",
        "    - `{\"type\": \"tool_end\", \"tool\": \"<name>\", \"message\": \"...\", \"summary\": \"<truncated output>\"}` ‚Äî tool finished.\n",
        "    - `{\"type\": \"token\", \"content\": \"<partial text>\"} ` ‚Äî incremental LLM text.\n",
        "    - `{\"type\": \"complete\", \"message\": \"Review completed\", \"full_response\": \"<full text>\"}`\n",
        "    - Final sentinel: `[DONE]`\n",
        "  - Your client reads with `response.iter_lines(decode_unicode=True)`, processes each `data: ...` JSON, and **stops on `[DONE]`**.\n",
        "\n",
        "> Notes  \n",
        "> ‚Ä¢ The streaming response uses Server-Sent Events (SSE) semantics; for browser `EventSource` you‚Äôd typically set `media_type=\"text/event-stream\"` (this demo uses a plain-text stream that works well with `requests`).  \n",
        "> ‚Ä¢ The non-streaming endpoint is ideal for simple automations; the streaming endpoint is better for live progress UIs/logs.\n"
      ],
      "id": "4BnnUk0faut-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "routes-core"
      },
      "outputs": [],
      "source": [
        "# API Request/Response Schemas\n",
        "class ReviewRequest(BaseModel):\n",
        "    patient_id: str\n",
        "\n",
        "class StreamingReviewRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    include_tool_calls: bool = True\n",
        "\n",
        "class ReviewResponse(BaseModel):\n",
        "    patient_id: str\n",
        "    decision: str\n",
        "    reasoning: str\n",
        "    care_recommendation: str\n",
        "    processing_time: float\n",
        "\n",
        "class HealthResponse(BaseModel):\n",
        "    status: str\n",
        "    timestamp: str\n",
        "    version: str\n",
        "\n",
        "# API endpoint to check API health\n",
        "@app.get(\"/health\", response_model=HealthResponse)\n",
        "async def health_check():\n",
        "    return HealthResponse(\n",
        "        status=\"‚úÖ API is Healthy\",\n",
        "        timestamp=time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        version=\"1.0.0\",\n",
        "    )\n",
        "\n",
        "# API endpoint to get list of all patients\n",
        "@app.get(\"/patients\")\n",
        "async def list_patients():\n",
        "    return {\n",
        "        \"patients\": [record[\"patient_id\"] for record in patient_records],\n",
        "        \"count\": len(patient_records),\n",
        "    }\n",
        "\n",
        "# API endpoint to get details of a specific patient\n",
        "@app.get(\"/patient/{patient_id}\")\n",
        "async def get_patient_details(patient_id: str):\n",
        "    for record in patient_records:\n",
        "        if record[\"patient_id\"] == patient_id:\n",
        "            return record\n",
        "    raise HTTPException(status_code=404, detail=f\"Patient {patient_id} not found\")\n",
        "\n",
        "# API endpoint to run utilization review on a patient - returns response after all processing is complete\n",
        "@app.post(\"/review/invoke\", response_model=ReviewResponse)\n",
        "async def review_patient(request: ReviewRequest):\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        patient_exists = any(r[\"patient_id\"] == request.patient_id for r in patient_records)\n",
        "        if not patient_exists:\n",
        "            raise HTTPException(status_code=404, detail=f\"Patient {request.patient_id} not found\")\n",
        "        # call agent in invoke mode and get final response after agent completes processing everything\n",
        "        prompt = f\"Review patient {request.patient_id} for procedure justification.\"\n",
        "        result = utilization_review_agent.invoke({\"messages\": [(\"user\", prompt)]}, {\"recursion_limit\": 150})\n",
        "        final_response = result[\"messages\"][-1].content\n",
        "\n",
        "        # Just for final formatting as per data schema\n",
        "        # you can also just return the above content as response\n",
        "        decision = reasoning = care_recommendation = \"\"\n",
        "        for line in final_response.strip().split(\"\\n\"):\n",
        "            if line.startswith(\"- Final Decision:\"):\n",
        "                decision = line.replace(\"- Final Decision:\", \"\").strip()\n",
        "            elif line.startswith(\"- Decision Reasoning:\"):\n",
        "                reasoning = line.replace(\"- Decision Reasoning:\", \"\").strip()\n",
        "            elif line.startswith(\"- Care recommendation or alternative steps:\"):\n",
        "                care_recommendation = line.replace(\"- Care recommendation or alternative steps:\", \"\").strip()\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "        return ReviewResponse(\n",
        "            patient_id=request.patient_id,\n",
        "            decision=decision,\n",
        "            reasoning=reasoning,\n",
        "            care_recommendation=care_recommendation,\n",
        "            processing_time=round(processing_time, 2),\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing review: {str(e)}\")\n",
        "\n",
        "# API endpoint to run utilization review on a patient - live streams intermediate processing and final results\n",
        "@app.post(\"/review/stream\")\n",
        "async def review_stream_sse(request: StreamingReviewRequest):\n",
        "    \"\"\"Stream the medical review process using Server-Sent Events (SSE).\"\"\"\n",
        "    # SSE is a communication mechanism where the server sends live updates to the client.\n",
        "    # The client initiates the connection, and the server streams data to the client over the same HTTP connection.\n",
        "\n",
        "    async def generate_sse() -> AsyncGenerator[str, None]:\n",
        "        try:\n",
        "            # Validate patient exists\n",
        "            patient_exists = any(r[\"patient_id\"] == request.patient_id for r in patient_records)\n",
        "            if not patient_exists:\n",
        "                yield f\"data: {json.dumps({'error': f'Patient {request.patient_id} not found'})}\\n\\n\"\n",
        "                return\n",
        "\n",
        "            # Send initial status\n",
        "            yield f\"data: {json.dumps({'status': 'starting', 'message': f'Starting review for patient {request.patient_id}'})}\\n\\n\"\n",
        "\n",
        "            prompt = f\"Review patient {request.patient_id} for procedure justification.\"\n",
        "\n",
        "            current_tool = None\n",
        "            collected_content = \"\"\n",
        "\n",
        "            # calls agent in async streaming mode to get live tokens as they are generated\n",
        "            # generates an async iterator of events in the agent which can be streamed live\n",
        "            async for event in utilization_review_agent.astream_events(\n",
        "                {\"messages\": [(\"user\", prompt)]},\n",
        "                version=\"v1\",\n",
        "                config={\"recursion_limit\": 25}\n",
        "            ):\n",
        "                event_type = event[\"event\"]\n",
        "                event_data = event.get(\"data\", {})\n",
        "                # Stream and Show that tool call event has started\n",
        "                if event_type == \"on_tool_start\":\n",
        "                    tool_name = event.get(\"name\", \"unknown_tool\")\n",
        "                    current_tool = tool_name\n",
        "                    if request.include_tool_calls:\n",
        "                        yield f\"data: {json.dumps({'type': 'tool_start', 'tool': tool_name, 'message': f'Executing {tool_name}...'})}\\n\\n\"\n",
        "                # Stream and Show that tool call event has ended\n",
        "                elif event_type == \"on_tool_end\":\n",
        "                    if request.include_tool_calls and current_tool:\n",
        "                        # Get the output safely\n",
        "                        output = event_data.get(\"output\", {})\n",
        "                        if isinstance(output, dict):\n",
        "                            # Summarize tool output (could even use llm summarizer optionally)\n",
        "                            summary = str(output)[:200] + \"...\" if len(str(output)) > 200 else str(output)\n",
        "                        else:\n",
        "                            summary = str(output)[:200] + \"...\" if len(str(output)) > 200 else str(output)\n",
        "\n",
        "                        yield f\"data: {json.dumps({'type': 'tool_end', 'tool': current_tool, 'message': f'Completed {current_tool}', 'summary': summary})}\\n\\n\"\n",
        "                    current_tool = None\n",
        "                # Stream and show content tokens from Agent (LLMs or Tool Calls)\n",
        "                elif event_type == \"on_chat_model_stream\":\n",
        "                    chunk = event_data.get(\"chunk\")\n",
        "                    if chunk and hasattr(chunk, 'content') and chunk.content:\n",
        "                        content = chunk.content\n",
        "                        collected_content += content\n",
        "                        yield f\"data: {json.dumps({'type': 'token', 'content': content})}\\n\\n\"\n",
        "\n",
        "            # Send final completion status\n",
        "            yield f\"data: {json.dumps({'type': 'complete', 'message': 'Review completed', 'full_response': collected_content})}\\n\\n\"\n",
        "            yield \"data: [DONE]\\n\\n\"\n",
        "\n",
        "        except Exception as e:\n",
        "            yield f\"data: {json.dumps({'error': f'Streaming error: {str(e)}'})}\\n\\n\"\n",
        "\n",
        "    return StreamingResponse(\n",
        "        generate_sse(),\n",
        "        media_type=\"text/plain\", # for browser (JS apis) you typically use media_type=\"text/event-stream\n",
        "        headers={\n",
        "            \"Cache-Control\": \"no-cache\",\n",
        "            \"Connection\": \"keep-alive\",\n",
        "            \"Content-Type\": \"text/plain\",\n",
        "        }\n",
        "    )\n"
      ],
      "id": "routes-core"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmyVYc9Maut-"
      },
      "source": [
        "## Deploy API on the Server\n",
        "\n",
        "This cell launches the FastAPI app **inside the notebook** by starting Uvicorn in a **background daemon thread**:\n",
        "\n",
        "- **`run_server_in_background(port=...)`**  \n",
        "  - Spawns `uvicorn.run(app, host=\"127.0.0.1\", port=port)` in a separate thread so you can keep using the notebook.  \n",
        "  - `time.sleep(5)` gives Uvicorn a moment to bind the port before you start sending requests.  \n",
        "  - Returns the thread handle (`server_thread`) for reference.\n",
        "\n",
        "- **Local-only bind**  \n",
        "  - The server binds to `127.0.0.1` (loopback) which is ideal for notebook testing.  \n",
        "  - Change to `0.0.0.0` only if you intentionally want external access (plus add auth and tighten CORS).\n",
        "\n",
        "- **Stopping the server**  \n",
        "  - In most notebook environments, daemon threads are not easily stopped mid-session; **restart the kernel** to fully stop the server, or avoid starting multiple instances on the same port.\n",
        "\n",
        "- **Production tip**  \n",
        "  - Package the app and run with a proper process manager, e.g.  \n",
        "    - `uvicorn app:app --host 0.0.0.0 --port 8000`  \n",
        "    - or `gunicorn -k uvicorn.workers.UvicornWorker app:app`  \n",
        "  - Add authentication, structured logging, and restrict CORS to trusted origins.\n",
        "  - OR you would package the agent code, API code and this startup code in a python file and then you would deploy it,\n",
        "  e.g.,\n",
        "  ```bash\n",
        "  /content# nohup python server.py &\n",
        "  ```"
      ],
      "id": "YmyVYc9Maut-"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_server_in_background(port: int = 8000):\n",
        "    \"\"\"Run the FastAPI server in a background thread (useful for Colab).\"\"\"\n",
        "    # In reality you would package the agent code, API code and this startup code in a python file\n",
        "    # and then you would deploy it e.g nohup python server.py\n",
        "    def run_server():\n",
        "        uvicorn.run(app, host=\"127.0.0.1\", port=port, log_level=\"info\")\n",
        "    thread = threading.Thread(target=run_server, daemon=True)\n",
        "    thread.start()\n",
        "    time.sleep(5)  # wait for startup\n",
        "    return thread"
      ],
      "metadata": {
        "id": "wSu_YenweCWG"
      },
      "id": "wSu_YenweCWG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server_thread = run_server_in_background(port=8010)\n",
        "print(\"Server running at http://127.0.0.1:8010\")"
      ],
      "metadata": {
        "id": "UJrDpbf7eHRk"
      },
      "id": "UJrDpbf7eHRk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Server API on your Client\n",
        "\n",
        "Use Python‚Äôs `requests` from the **same notebook** to call and use the API you just deployed."
      ],
      "metadata": {
        "id": "1NGRf9i1Eyjm"
      },
      "id": "1NGRf9i1Eyjm"
    },
    {
      "cell_type": "code",
      "source": [
        "API_PORT=8010\n",
        "API_URL = f\"http://127.0.0.1:{API_PORT}\""
      ],
      "metadata": {
        "id": "wd8Fol6YeOlk"
      },
      "id": "wd8Fol6YeOlk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check API Health"
      ],
      "metadata": {
        "id": "mBZApZGlE5-P"
      },
      "id": "mBZApZGlE5-P"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    r = requests.get(f\"{API_URL}/health\", timeout=30)\n",
        "    print(\"Health:\", r.status_code, r.json())\n",
        "except Exception as e:\n",
        "    print(\"Health check failed:\", e)"
      ],
      "metadata": {
        "id": "n8jme3PjE9cL"
      },
      "id": "n8jme3PjE9cL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get all patients in the DB"
      ],
      "metadata": {
        "id": "wDxqGTYyFIba"
      },
      "id": "wDxqGTYyFIba"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    r = requests.get(f\"{API_URL}/patients\", timeout=30)\n",
        "    print(\"Patients:\", r.json())\n",
        "except Exception as e:\n",
        "    print(\"List patients failed:\", e)"
      ],
      "metadata": {
        "id": "_abMrlNdel4O"
      },
      "id": "_abMrlNdel4O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get specific patient record details"
      ],
      "metadata": {
        "id": "9ubN8cd5FbRb"
      },
      "id": "9ubN8cd5FbRb"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    r = requests.get(f\"{API_URL}/patient/P101\", timeout=10)\n",
        "    print(\"Patient P101:\")\n",
        "    if r.status_code == 200:\n",
        "        d = r.json()\n",
        "        print(\"  ->\", d)\n",
        "except Exception as e:\n",
        "    print(\"Patient details failed:\", e)"
      ],
      "metadata": {
        "id": "WfmCQ8Lye9XS"
      },
      "id": "WfmCQ8Lye9XS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Utilization Review on patients - Invoke Mode"
      ],
      "metadata": {
        "id": "cmvlJ4ctGvWi"
      },
      "id": "cmvlJ4ctGvWi"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import JSON, display\n",
        "\n",
        "for pid in [\"P101\", \"P102\"]:\n",
        "    print('-'*25)\n",
        "    try:\n",
        "        r = requests.post(f\"{API_URL}/review/invoke\", json={\"patient_id\": pid}, timeout=60)\n",
        "        print(f\"Review {pid}:\")\n",
        "        if r.status_code == 200:\n",
        "            display(JSON(r.json()))\n",
        "        else:\n",
        "            print(r.text)\n",
        "    except Exception as e:\n",
        "        print(f\"Review {pid} failed:\", e)\n",
        "    print('-'*25)"
      ],
      "metadata": {
        "id": "5WFKSpuIfVbJ"
      },
      "id": "5WFKSpuIfVbJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Utilization Review on patients - Live Streaming Mode"
      ],
      "metadata": {
        "id": "LRGOaQhhPwyd"
      },
      "id": "LRGOaQhhPwyd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get streaming response formatting utility functions"
      ],
      "metadata": {
        "id": "veA-168jQaOW"
      },
      "id": "veA-168jQaOW"
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1dSyjcjlFoZpYEqv4P9Oi0-kU2gIoolMB"
      ],
      "metadata": {
        "id": "CAOXCXlNQeY_"
      },
      "id": "CAOXCXlNQeY_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Simple Formatting of Streaming Results"
      ],
      "metadata": {
        "id": "JUsotZQfP2T2"
      },
      "id": "JUsotZQfP2T2"
    },
    {
      "cell_type": "code",
      "source": [
        "from agent_utils import format_streaming_results_simple\n",
        "\n",
        "patient_id = \"P104\"\n",
        "print(\"=\" * 80)\n",
        "print(f\"üè• MEDICAL REVIEW AGENT - STREAMING ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"üìã Patient ID: {patient_id}\")\n",
        "print(f\"üïê Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{API_URL}/review/stream\",\n",
        "        json={\"patient_id\": patient_id, \"include_tool_calls\": True},\n",
        "        stream=True,\n",
        "        timeout=120\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ Connection established - Starting review...\\n\")\n",
        "        for line in response.iter_lines(decode_unicode=True):\n",
        "            if line and line.startswith('data: '):\n",
        "                # get the streaming data\n",
        "                data_part = line[6:] # removes data: prefix\n",
        "                # check if agent has finished processing\n",
        "                if data_part == \"[DONE]\":\n",
        "                    print(\"\\n\" + \"=\" * 80)\n",
        "                    print(\"‚úÖ REVIEW COMPLETED SUCCESSFULLY\")\n",
        "                    print(\"=\" * 80)\n",
        "                    break\n",
        "                # stream and show agent tokens live\n",
        "                format_streaming_results_simple(data_part)\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå FAILED TO CONNECT\")\n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        print(f\"Response: {response.text}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå STREAMING ERROR: {e}\")\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "I7S0dANOH_Ob"
      },
      "id": "I7S0dANOH_Ob",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Detailed Formatting of Streaming Results"
      ],
      "metadata": {
        "id": "rjsKI33VRBgE"
      },
      "id": "rjsKI33VRBgE"
    },
    {
      "cell_type": "code",
      "source": [
        "from agent_utils import format_streaming_results_detailed\n",
        "\n",
        "patient_id = \"P104\"\n",
        "print(\"=\" * 80)\n",
        "print(f\"üè• MEDICAL REVIEW AGENT - STREAMING ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"üìã Patient ID: {patient_id}\")\n",
        "print(f\"üïê Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{API_URL}/review/stream\",\n",
        "        json={\"patient_id\": patient_id, \"include_tool_calls\": True},\n",
        "        stream=True,\n",
        "        timeout=120\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ Connection established - Starting review...\\n\")\n",
        "        state = {\"tool_counter\": 0, \"current_section\": None}\n",
        "        for line in response.iter_lines(decode_unicode=True):\n",
        "            if line and line.startswith('data: '):\n",
        "                # get the streaming data\n",
        "                data_part = line[6:] # removes data: prefix\n",
        "                # check if agent has finished processing\n",
        "                if data_part == \"[DONE]\":\n",
        "                    print(\"\\n\" + \"=\" * 80)\n",
        "                    print(\"‚úÖ REVIEW COMPLETED SUCCESSFULLY\")\n",
        "                    print(\"=\" * 80)\n",
        "                    break\n",
        "                # stream and show agent tokens live\n",
        "                format_streaming_results_detailed(data_part, state)\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå FAILED TO CONNECT\")\n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        print(f\"Response: {response.text}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå STREAMING ERROR: {e}\")\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "ML5VksvbHXrH"
      },
      "id": "ML5VksvbHXrH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
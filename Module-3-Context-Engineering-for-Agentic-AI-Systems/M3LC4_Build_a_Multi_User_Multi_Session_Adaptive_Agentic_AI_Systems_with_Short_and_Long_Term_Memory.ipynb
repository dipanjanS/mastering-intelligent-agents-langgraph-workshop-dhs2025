{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoO4xVL1uha+vSSa40n4SR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/mastering-intelligent-agents-langgraph-workshop-dhs2025/blob/main/Module-3-Context-Engineering-for-Agentic-AI-Systems/M3LC4_Build_a_Multi_User_Multi_Session_Adaptive_Agentic_AI_Systems_with_Short_and_Long_Term_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Multi-User - Multi-Session Adaptive Agentic AI Systems with Short and Long-Term Memory with LangGraph and LangMem\n",
        "\n",
        "**How does a conversational agent store memories?**\n",
        "\n",
        "For example in the ChatGPT platform you can explicitely call out to ChatGPT when it should store something about you.\n",
        "\n",
        "![](https://i.imgur.com/7vzt6Hf.png)\n",
        "\n",
        "You can then go and check out all your past memories in the settings in ChatGPT which basically stores it as a list of facts about you and your preferences.\n",
        "\n",
        "![](https://i.imgur.com/qf4hF1Y.png)\n",
        "\n",
        "\n",
        "\n",
        "In this notebook, we design and build an advanced **Agentic AI system** that can handle **multiple users**, each with **multiple sessions**, while maintaining both **short-term** (thread-level) and **long-term** (persistent, user-specific) memory. This system leverages the power of [LangGraph](https://github.com/langchain-ai/langgraph) for agent orchestration and [LangMem](https://github.com/langchain-ai/langmem) for structured memory management.\n",
        "\n",
        "Here is the agent architecture we will be building.\n",
        "\n",
        "![](https://i.imgur.com/ifmmwPJ.png)\n",
        "\n",
        "\n",
        "\n",
        "### Key Features Covered:\n",
        "- **Short-Term Memory**: Session-scoped context maintained across turns using LangGraph’s checkpointer.\n",
        "- **Long-Term Memory**: User-specific memory stored using LangMem, enabling agents to recall preferences, history, and facts across sessions.\n",
        "- **Multi-User Support**: Each user has a unique memory namespace and thread-based session context.\n",
        "- **Tool-Augmented Agent**: The agent is equipped with tools for web search, memory search, and memory update using Tavily and LangMem utilities.\n",
        "- **Agent Design**: Implements a ReAct-style graph where the agent reasons, invokes tools, observes outputs, and continues reasoning.\n",
        "- **Mentoring Use Case**: The system prompt turns the agent into a personalized AI tutor that adapts its behavior based on stored user data.\n",
        "- **Streaming Execution**: Uses `agent.stream(...)` to interactively respond to user queries while updating memory in real time.\n",
        "- **Multiple Session Runs**: Demonstrates agent behavior across multiple sessions and users, showcasing memory recall, adaptation, and evolution.\n",
        "\n",
        "This notebook serves as a complete walkthrough for building **adaptive, memory-aware agents** that personalize over time - useful in education, customer support, healthcare, finance, and more.\n"
      ],
      "metadata": {
        "id": "9omQHTjeA8uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "DGN6Yr7V-z4c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgGjfUlRobgQ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.27 langchain-community==0.3.27 langchain-openai==0.3.30 langgraph==0.6.5 langmem==0.0.29 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Authentication and LLM Client\n",
        "\n",
        "Here we authenticate and connect to necessary LLM using OpenAI Authentication"
      ],
      "metadata": {
        "id": "crTRTYdTKxGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# OpenAI API Key (for chat & embeddings)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key (https://platform.openai.com/account/api-keys):\\n\")\n",
        "\n",
        "# Tavily API Key (for web search)\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key (https://app.tavily.com/home):\\n\")"
      ],
      "metadata": {
        "id": "L3bjBQ7vOVX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1dSyjcjlFoZpYEqv4P9Oi0-kU2gIoolMB"
      ],
      "metadata": {
        "id": "8xcOckb5OsH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tools for AI Agent"
      ],
      "metadata": {
        "id": "kBwMcZCY_OEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "from langchain.tools import tool\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.retrievers import ArxivRetriever\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Tool for web search on general health topics\n",
        "# Tavily Web Search\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"\n",
        "    Search the web for general or up-to-date information on healthcare topics.\n",
        "\n",
        "    Inputs:\n",
        "    - query (str): The search query string. Should describe the healthcare topic or information you want to find.\n",
        "\n",
        "    Outputs:\n",
        "    - list: A list of up to 3 formatted strings, each containing:\n",
        "        - Title of the search result\n",
        "        - Content extracted from the page\n",
        "        - Source URL\n",
        "    \"\"\"\n",
        "    results = tavily_search.raw_results(query=query, max_results=3, search_depth='advanced',\n",
        "                                        include_answer=False, include_raw_content=True)\n",
        "    docs = results['results']\n",
        "    docs = [doc for doc in docs if doc.get(\"raw_content\") is not None]\n",
        "    docs = ['## Title\\n'+doc['title']+'\\n\\n'+'## Content\\n'+doc['raw_content']+'\\n\\n'+'##Source\\n'+doc['url'] for doc in docs]\n",
        "    return docs\n",
        "\n",
        "\n",
        "namespace = (\"agent_memories\", \"{user_id}\")\n",
        "MEMORY_MGMT_SYS_PROMPT = \"\"\"Proactively call this tool when you:\n",
        "\n",
        "1. Identify a new **USER preference**, especially related to:\n",
        "   - Learning goals and skill development areas\n",
        "   - Topics of interest and subject matter focus\n",
        "   - Preferred teaching or mentoring style\n",
        "   - Communication tone, level of detail, and pacing\n",
        "   - Formats, examples, or resources the USER finds helpful\n",
        "2. Receive an explicit USER request to **remember** something or adjust your behavior.\n",
        "3. Are in an ongoing mentoring conversation and want to **record important context** that will help personalize future guidance.\n",
        "4. ONLY UPDATE when an older memory needs replacing else keep ADD NEW MEMORIES based on new user informaiton as per point 1.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "create_mem_tool = create_manage_memory_tool(namespace=namespace,\n",
        "                                            instructions=MEMORY_MGMT_SYS_PROMPT)\n",
        "search_mem_tool = create_search_memory_tool(namespace)\n",
        "tools = [search_web, create_mem_tool, search_mem_tool]\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "llm_with_tools = llm.bind_tools(tools=tools)"
      ],
      "metadata": {
        "id": "KpX0a2SkPhbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the AI Agent"
      ],
      "metadata": {
        "id": "x9pEoDfc_aHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add the System Instructions Prompt"
      ],
      "metadata": {
        "id": "fGAsJJGW_ccN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "AGENT_INSTRUCTIONS = \"\"\"\n",
        "You are an **AI Tutor and Mentor** specializing in **AI, Data Science, Generative AI, and Agentic AI**.\n",
        "Your role is to explain, teach, and guide the USER in a clear, engaging, and personalized way.\n",
        "Adapt your explanations to the USER’s background, preferences, and learning goals, making complex concepts easy to understand while providing depth when needed.\n",
        "\n",
        "## Core Responsibilities\n",
        "- Always search for existing memories first before answering any questions. Do NOT answer questions before checking existing memories.\n",
        "- When searching for memories, create a **clear, concise, and optimal search query** that captures the key information needed from past interactions instead of directly using the full user message.\n",
        "- Add any new information about the user or update existing memories as needed based on details mentioned below.\n",
        "- Answer USER queries accurately and comprehensively by combining:\n",
        "  - Retrieved memories\n",
        "  - Your own internal knowledge\n",
        "  - Web search results when needed\n",
        "- Adjust style, tone, and complexity based on USER preferences and prior conversations.\n",
        "- Actively maintain and leverage long-term USER context by **storing new information** and **retrieving relevant past information** during the conversation.\n",
        "- Use web search when needed to ensure responses are **factual, relevant, and up-to-date**.\n",
        "- Maintain a respectful, supportive, and encouraging mentoring tone.\n",
        "\n",
        "## Available Tools and Usage Rules\n",
        "You must actively use these tools during the conversation as needed:\n",
        "\n",
        "1. **Manage Memory Tool** (`create_manage_memory_tool`)\n",
        "   - Store **new** USER preferences, learning goals, or important information context as soon as they are discovered.\n",
        "   - Only **update** (append or replace) an existing memory if new user information directly CONTRADICTS or REPLACES older stored information.\n",
        "\n",
        "2. **Search Memory Tool** (`create_search_memory_tool`)\n",
        "   - Retrieve relevant USER memories (preferences, progress, past discussions) **before answering** if they could improve personalization or continuity.\n",
        "   - Always construct a **focused and relevant search query** based on the user’s request or current context.\n",
        "\n",
        "3. **Web Search Tool** (`search_web`)\n",
        "   - Use when the query requires:\n",
        "     - Recent or time-sensitive information\n",
        "     - Additional detailed information or examples\n",
        "     - Code samples or up-to-date implementations\n",
        "\n",
        "## Workflow to follow for each user interaction step-by-step:\n",
        "1. **Search memories first** with `create_search_memory_tool`:\n",
        "   - Construct an **optimal query** summarizing the key details you need to recall.\n",
        "   - Use retrieved results to personalize your upcoming response.\n",
        "2. **Add new memories immediately** with `create_manage_memory_tool` when new details are learned about the USER:\n",
        "   - Preferences\n",
        "   - New information about themselves\n",
        "   - Likes or dislikes\n",
        "   - Topics they want to learn about\n",
        "   - Prefer adding new memories unless they directly contradict existing ones, in which case update the memory instead.\n",
        "3. **Answer the USER’s query** by combining:\n",
        "   - Retrieved memories for personalization\n",
        "   - Your internal knowledge of the domain\n",
        "   - Web search results when needed (if unsure, researching, or the topic requires current information)\n",
        "4. When using **web search**, always cite your sources.\n",
        "5. Maintain conversation continuity across sessions by retrieving and applying stored memories.\n",
        "6. Be proactive in suggesting related topics, resources, or next steps.\n",
        "7. Use clear, structured explanations with optional technical depth if the USER requests it.\n",
        "\n",
        "## Style & Tone\n",
        "- Personalize responses based on stored preferences and context.\n",
        "- Be adaptable: explain concepts in multiple ways if the USER needs clarification.\n",
        "- Present information in logical steps or bullet points.\n",
        "- Balance theory with practical examples, applications, or exercises.\n",
        "\"\"\"\n",
        "\n",
        "SYS_PROMPT = SystemMessage(content=AGENT_INSTRUCTIONS)"
      ],
      "metadata": {
        "id": "8x9B_PLzUGnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Agent Graph with Long and Short Term memory"
      ],
      "metadata": {
        "id": "guVt6peM_fpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "6w7jIbU-Uz37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from IPython.display import display, Image, Markdown\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "# Create the node function that handles reasoning and planning using the LLM\n",
        "def tool_calling_llm(state: State) -> State:\n",
        "    # Extract the current conversation history from the state\n",
        "    current_state = state[\"messages\"]\n",
        "\n",
        "    # Prepend the system instructions to the current message history\n",
        "    state_with_instructions = [SYS_PROMPT] + current_state\n",
        "\n",
        "    # Call the LLM to generate a new message (either a response or a tool call request)\n",
        "    response = [llm_with_tools.invoke(state_with_instructions)]\n",
        "\n",
        "    # Return the updated state containing the new message\n",
        "    return {\"messages\": response}\n",
        "\n",
        "# Build the graph\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"agent\", tool_calling_llm)\n",
        "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "\n",
        "# Add edges\n",
        "builder.add_edge(START, \"agent\")\n",
        "# Conditional edge\n",
        "builder.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tools_condition, # conditional routing function\n",
        "    {\n",
        "        \"tools\": \"tools\", # If the latest message (result) from LLM is a tool call request -> tools_condition routes to tools\n",
        "        \"__end__\": END # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
        "    }\n",
        ")\n",
        "builder.add_edge(\"tools\", \"agent\") # this is the key feedback loop in the agentic system\n",
        "\n",
        "# Compile Agent Graph\n",
        "short_term_memory = InMemorySaver()\n",
        "long_term_memory_store = InMemoryStore(\n",
        "    index={\n",
        "        \"dims\": 1536,\n",
        "        \"embed\": \"openai:text-embedding-3-small\"\n",
        "    }\n",
        ")\n",
        "agent = builder.compile(checkpointer=short_term_memory,\n",
        "                        store=long_term_memory_store)"
      ],
      "metadata": {
        "id": "pwRSuqKZU2L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent"
      ],
      "metadata": {
        "id": "bikzNbt-XS-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run and Test the Agent"
      ],
      "metadata": {
        "id": "EG_wVDCy_jIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agent_utils import format_message\n",
        "\n",
        "def call_mentor_agent(agent, query, user_id, session_id, verbose=False):\n",
        "\n",
        "    for event in agent.stream(\n",
        "        input={\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "        config={\"configurable\": {\"user_id\": user_id, \"thread_id\": session_id}},\n",
        "        stream_mode='values' #returns full agent state with all messages including updates\n",
        "    ):\n",
        "        if verbose:\n",
        "            format_message(event[\"messages\"][-1])\n",
        "\n",
        "    print('\\n\\nFinal Response:\\n')\n",
        "    display(Markdown(event[\"messages\"][-1].content))\n",
        "    return event[\"messages\"]"
      ],
      "metadata": {
        "id": "4E26OdZmXUoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User 1 - Session 1"
      ],
      "metadata": {
        "id": "t7Xx_M3BAHSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = 'user_dj'\n",
        "user_session = 'dj-session-001'\n",
        "query = \"\"\"Hi, I'm Dipanjan but you can call me DJ,\n",
        "Please remember I'm proficient in AI, Generative AI and Agentic AI.\n",
        "I also prefer working in Python and right now\n",
        "\n",
        "My first question is - Explain CoT prompting in brief\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "nSYR1pneXcE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_session = 'dj-session-001'\n",
        "query = \"\"\"Please remember I am working on healthcare insurance projects these days,\n",
        "so examples from that domain is helpful in the future.\n",
        "\n",
        "Research on what is a ReAct agent and explain to me with a simple example please\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "YdGgHfbDf5pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory_store.search((\"agent_memories\",))"
      ],
      "metadata": {
        "id": "tJgk8UVc803D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User 1 - Session 2"
      ],
      "metadata": {
        "id": "HfNdlJXlAMzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = 'user_dj'\n",
        "user_session = 'dj-session-002'\n",
        "query = \"\"\"hey, do you remember me?\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "BomvOhwkcnQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_session = 'dj-session-002'\n",
        "query = \"\"\"Please remember that I am now working on a financial project in Generative AI so please show me examples only for this domain.\n",
        "\n",
        "Explain to me what is Agentic AI vs. Generative AI with some examples\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "xKeoeqRzwGDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory_store.search((\"agent_memories\",))"
      ],
      "metadata": {
        "id": "HB8b60qD9DSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User 1 - Session 3"
      ],
      "metadata": {
        "id": "R3z0ewxNAPSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = 'user_dj'\n",
        "user_session = 'dj-session-003'\n",
        "query = \"\"\"Tell me what you know about me.\n",
        "\n",
        "Also give me a simple example of machine learning vs deep learning\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "zUE7rys99Htu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory_store.search((\"agent_memories\",))"
      ],
      "metadata": {
        "id": "_LQrXzbWKJ7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User 2 - Session 1"
      ],
      "metadata": {
        "id": "ATYqdsxYAZkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = 'user_mike'\n",
        "user_session = 'mm-session-001'\n",
        "query = \"\"\"Hi I'm Mike Murdock but you can call me daredevil.\n",
        "I love fighting crime and working with other superheroes.\n",
        "\n",
        "Can you tell me which other superheroes are really popular in Marvel?\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "zV_LrvZOwEcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_session = 'mm-session-001'\n",
        "query = \"\"\"My friends include the fantastic four and spiderman, please remember this.\n",
        "\n",
        "Do you know any other superheroes I can work with together?\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "6XHGR053w4lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory_store.search((\"agent_memories\",))"
      ],
      "metadata": {
        "id": "BPE1pIEW9lz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = 'mm-session-001'\n",
        "query = \"\"\"Please add Iron Man and Black Panther to my list of friends also\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, session, verbose=True)"
      ],
      "metadata": {
        "id": "PjsQj4sjxQYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory_store.search((\"agent_memories\",))"
      ],
      "metadata": {
        "id": "VYfOw7A_DEnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User 2 - Session 2"
      ],
      "metadata": {
        "id": "eXTp9b1tAxnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = 'user_mike'\n",
        "user_session = 'mm-session-002'\n",
        "query = \"\"\"Hi! There is a huge threat, Galactus is coming to earth and we need to stop him!\n",
        "\n",
        "Search my friend list and tell me who could I call for helping me out to protect the world!\n",
        "\"\"\"\n",
        "response = call_mentor_agent(agent, query, user, user_session, verbose=True)"
      ],
      "metadata": {
        "id": "t9BhTYyvxbXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_term_memory_store.search((\"agent_memories\",))"
      ],
      "metadata": {
        "id": "H3ZDMURCcpRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
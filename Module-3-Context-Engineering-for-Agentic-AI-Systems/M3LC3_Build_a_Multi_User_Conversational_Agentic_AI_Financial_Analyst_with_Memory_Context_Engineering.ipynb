{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc82imDK6pqZv5BAugYwvq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/mastering-intelligent-agents-langgraph-workshop-dhs2025/blob/main/Module-3-Context-Engineering-for-Agentic-AI-Systems/M3LC3_Build_a_Multi_User_Conversational_Agentic_AI_Financial_Analyst_with_Memory_Context_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Multi-User Conversational Financial Analyst Tool-Use AI Agent with In-Memory Persistence with LangGraph"
      ],
      "metadata": {
        "id": "8pdRDlVs1MJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project will focus on building a Tool-Use Agentic AI System which acts as a Financial Analyst & Advisor. This agent will be conversational and can handle multiple user-sessions with their own separate conversational history.\n",
        "\n",
        "The first project here will build a conversational tool-use agentic system with in-memory persistence.\n",
        "\n",
        "![](https://i.imgur.com/2xSAz1e.png)\n",
        "\n",
        "### Financial Analyst Tool-Use Agentic AI System with In-Memory Persistence\n",
        "\n",
        "This project focuses on building a **Tool-Use Agentic AI System** that acts as a Financial Analyst & Advisor. The agent will be conversational and can handle multiple user sessions with their own separate conversational history. By leveraging the `create_react_agent` function from **LangGraph**, this project adds in-memory persistence for enhanced user interaction continuity. The workflow comprises the following components:\n",
        "\n",
        "1. **Agent System Prompt**:\n",
        "   - The agent validates input queries for relevance and specificity.\n",
        "   - It provides detailed market analysis or stock-specific insights depending on the user's query.\n",
        "   - For invalid queries, the agent responds professionally and guides the user appropriately.\n",
        "   - The system delivers concise, professional responses emphasizing data clarity and accuracy.\n",
        "\n",
        "   **Flows**:\n",
        "   - **Flow 1**: For general market trends, the agent analyzes data and suggests stock opportunities using tools like `SEARCH_WEB` and `GET_GENERAL_MARKET_DATA`.\n",
        "   - **Flow 2**: For stock-specific queries, the agent validates the stock ticker, retrieves relevant data, and provides insights using tools such as `GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS` and `GET_STOCK_PRICE_METRICS`.\n",
        "\n",
        "2. **Financial Analysis Tools**:\n",
        "   The system integrates multiple tools to ensure comprehensive and precise insights:\n",
        "   - **GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS**: Provides insights into key financial metrics such as P/E ratio, ROE, etc.\n",
        "   - **GET_STOCK_NEWS**: Extracts the latest news and updates related to stocks or markets.\n",
        "   - **GET_GENERAL_MARKET_DATA**: Fetches data on overall market trends and performance.\n",
        "   - **GET_STOCK_TICKER**: Validates and fetches stock ticker symbols based on user queries.\n",
        "   - **GET_STOCK_PRICE_METRICS**: Retrieves price trends, performance, and metrics for specific stocks.\n",
        "\n",
        "3. **Stock Market Data Providers**:\n",
        "   The system ensures real-time, reliable data by integrating with top providers like Yahoo Finance, Finviz, TMX, Cboe, and more, through platforms such as **OpenBB**.\n",
        "\n",
        "4. **Memory Module**:\n",
        "   - A memory module is introduced to store and manage user-specific conversational histories.\n",
        "   - This enables the agent to maintain session continuity and provide context-aware responses for recurring users or prolonged interactions. __Here we store this in-memory.__\n",
        "\n",
        "5. **ReAct Reasoning Framework**:\n",
        "   - The system employs **ReAct reasoning**, combining logical deduction with dynamic tool usage. This framework ensures precise and actionable results by dynamically selecting the right tools based on the query.\n",
        "\n",
        "6. **Final Response**:\n",
        "   - After processing the data from tool calls, the agentic system generates the final response.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NYBpZTjLnEXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, LangGraph and LangChain dependencies"
      ],
      "metadata": {
        "id": "9hEI3WL328vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.27 langchain-openai==0.3.30 langgraph==0.6.5 langchain-community==0.3.27 langgraph-checkpoint-sqlite==2.0.11 --quiet"
      ],
      "metadata": {
        "id": "2evPp14fy258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenBB"
      ],
      "metadata": {
        "id": "pSE8EoRXyuxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openbb[all]==4.4.5 --quiet"
      ],
      "metadata": {
        "id": "fO4gOIVIjGH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "H9c37cLnSrbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ],
      "metadata": {
        "id": "cv3JzCEx_PAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter OpenBB Key\n",
        "\n",
        "Get a free API key from [here](https://my.openbb.co/app/platform/pat)"
      ],
      "metadata": {
        "id": "-tsLsa9b3Dxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENBB_PAT = getpass('Enter OpenBB Personal Access Token (PAT): ')"
      ],
      "metadata": {
        "id": "q2sKDYgEqOaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ],
      "metadata": {
        "id": "ucWRRI3QztL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ],
      "metadata": {
        "id": "mK-1WLzOrJdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "1T0s0um5Svfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openbb import obb\n",
        "# takes 1 min to setup\n",
        "obb.account.login(pat=OPENBB_PAT)"
      ],
      "metadata": {
        "id": "V4a3LQeClFoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FMP_API_KEY = getpass('Enter Financial Modeling Prep Key (FMP key): ')\n",
        "obb.user.credentials.fmp_api_key = FMP_API_KEY"
      ],
      "metadata": {
        "id": "PoZ1gJk0_bwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obb.user.credentials"
      ],
      "metadata": {
        "id": "NAF6JDPZ_vwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Financial Tools\n",
        "\n",
        "**Financial Analysis Tools**:\n",
        "   The system integrates multiple tools to get useful financial data and metrics:\n",
        "\n",
        "   - **GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS**: Provides insights into key financial metrics such as P/E ratio, ROE, etc.\n",
        "   - **GET_STOCK_NEWS**: Extracts the latest news and updates related to stocks or markets.\n",
        "   - **GET_GENERAL_MARKET_DATA**: Fetches data on overall market trends and performance.\n",
        "   - **GET_STOCK_TICKER**: Validates and fetches stock ticker symbols based on user queries.\n",
        "   - **GET_STOCK_PRICE_METRICS**: Retrieves price trends, performance, and metrics for specific stocks."
      ],
      "metadata": {
        "id": "TW0QaP_RzG2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_core.tools import tool\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_stock_ticker_symbol(stock_name: str) -> str:\n",
        "    \"\"\"Look up a company's stock identifier.\n",
        "\n",
        "    Args:\n",
        "        stock_name: Company name or partial name to search.\n",
        "\n",
        "    Returns:\n",
        "        A markdown-formatted table with potential matches and identifiers\n",
        "        (e.g., ticker, company name, CIK).\n",
        "\n",
        "    Notes:\n",
        "        - Uses OpenBB `equity.search` with provider \"sec\".\n",
        "        - Results may include multiple matches for ambiguous names.\n",
        "    \"\"\"\n",
        "    # Use OpenBB to search for stock ticker symbol and company details by name.\n",
        "    # The provider \"sec\" fetches data from the U.S. Securities and Exchange Commission (SEC).\n",
        "    try:\n",
        "        res = obb.equity.search(stock_name, provider=\"sec\")\n",
        "\n",
        "        # Convert the result to a DataFrame and format it as markdown for readability.\n",
        "        stock_ticker_details = res.to_df().to_markdown()\n",
        "\n",
        "        # Prepare the output with the stock details.\n",
        "        output = \"\"\"Here are the details of the company and its stock ticker symbol:\\n\\n\"\"\" + stock_ticker_details\n",
        "    except Exception as e:\n",
        "        output = (\n",
        "            \"Please broaden your search and try again. \"\n",
        "            \"Error encountered for search with query: \" + stock_name +\n",
        "            f\"\\n\\nError details: {str(e)}\"\n",
        "        )\n",
        "    return output\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_stock_price_metrics(stock_ticker: str) -> str:\n",
        "    \"\"\"Retrieve quote, performance stats, and 1-year price history for a ticker.\n",
        "\n",
        "    Args:\n",
        "        stock_ticker: Exchange ticker symbol (e.g., \"AAPL\").\n",
        "\n",
        "    Returns:\n",
        "        A markdown-formatted string containing:\n",
        "          - Price Quote Metrics (provider: cboe)\n",
        "          - Price Performance Metrics (provider: finviz)\n",
        "          - Daily Historical Prices for the past year (provider: yfinance)\n",
        "\n",
        "    Notes:\n",
        "        - Data sources have different refresh cadences and may lag real time.\n",
        "        - Historical range is computed from the current date minus 365 days.\n",
        "    \"\"\"\n",
        "    # Fetch the latest stock price quote using \"cboe\" provider.\n",
        "    res = obb.equity.price.quote(stock_ticker, provider='cboe')\n",
        "    price_quote = res.to_df().to_markdown()\n",
        "\n",
        "    # Retrieve stock price performance metrics (e.g., percentage change) using \"finviz\" provider.\n",
        "    res = obb.equity.price.performance(symbol=stock_ticker, provider='finviz')\n",
        "    price_performance = res.to_df().to_markdown()\n",
        "\n",
        "    # Fetch historical price data for the past year using \"yfinance\" provider.\n",
        "    end_date = datetime.now()\n",
        "    start_date = (end_date - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "    res = obb.equity.price.historical(symbol=stock_ticker, start_date=start_date,\n",
        "                                      interval='1d', provider='yfinance')\n",
        "    price_historical = res.to_df().to_markdown()\n",
        "\n",
        "    # Combine the results into a formatted output.\n",
        "    output = (\"\"\"Here are the stock price metrics and data for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" +\n",
        "              \"Price Quote Metrics:\\n\\n\" + price_quote +\n",
        "              \"\\n\\nPrice Performance Metrics:\\n\\n\" + price_performance +\n",
        "              \"\\n\\nPrice Historical Data:\\n\\n\" + price_historical)\n",
        "    return output\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_stock_fundamental_indicator_metrics(stock_ticker: str) -> str:\n",
        "    \"\"\"Fetch annual fundamental metrics for a company.\n",
        "\n",
        "    Args:\n",
        "        stock_ticker: Exchange ticker symbol (e.g., \"MSFT\").\n",
        "\n",
        "    Returns:\n",
        "        A markdown-formatted table of key fundamental ratios and metrics for up to the last\n",
        "        10 annual periods.\n",
        "\n",
        "    Notes:\n",
        "        - Uses OpenBB `equity.fundamental.metrics` with provider \"yfinance\" and \"fmp.\n",
        "        - Metric availability varies by company and period.\n",
        "    \"\"\"\n",
        "    # Retrieve fundamental financial ratios (e.g., P/E ratio, ROE) using \"fmp\" provider.\n",
        "    res = obb.equity.fundamental.ratios(symbol=stock_ticker, period='annual',\n",
        "                                        limit=10, provider='fmp')\n",
        "    fundamental_ratios = res.to_df().to_markdown()\n",
        "\n",
        "    # Fetch additional fundamental metrics (e.g., EBITDA, revenue growth) using \"yfinance\" provider.\n",
        "    res = obb.equity.fundamental.metrics(symbol=stock_ticker, period='annual',\n",
        "                                         limit=10, provider='yfinance')\n",
        "    fundamental_metrics = res.to_df().to_markdown()\n",
        "\n",
        "    # Combine fundamental ratios and metrics into a single output.\n",
        "    output = (\"\"\"Here are the fundamental indicator metrics and data for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" +\n",
        "              \"Fundamental Ratios:\\n\\n\" + fundamental_ratios +\n",
        "              \"\\n\\nFundamental Metrics:\\n\\n\" + fundamental_metrics)\n",
        "    return output\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_stock_news(stock_ticker: str, query: str) -> str:\n",
        "    \"\"\"Collect recent company news and augment with web results.\n",
        "\n",
        "    Args:\n",
        "        stock_ticker: Exchange ticker symbol (e.g., \"NVDA\").\n",
        "        query: Free-text query about company name to guide additional web search context.\n",
        "\n",
        "    Returns:\n",
        "        A markdown-formatted string with:\n",
        "          - Headlines from the last 45 days for the given ticker (provider: yfinance)\n",
        "          - A short set of detailed articles from Tavily web search\n",
        "\n",
        "    Notes:\n",
        "        - Provider fields differ by source; this tool normalizes to title and text where possible.\n",
        "        - Tavily results include raw content when available.\n",
        "    \"\"\"\n",
        "    # Define the date range to fetch news (last 45 days).\n",
        "    end_date = datetime.now()\n",
        "    start_date = (end_date - timedelta(days=45)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Retrieve news headlines for the stock using \"tmx\" provider. - Changed to yfinance as tmx right now is not sending news for some sources\n",
        "    res = obb.news.company(symbol=stock_ticker, start_date=start_date, provider='yfinance', limit=100)\n",
        "    news = res.to_df()\n",
        "\n",
        "    # Extract relevant columns (symbols and titles) and format as markdown.\n",
        "    news = news[['title', 'text']]  # change column names based on provider - for tmx it will be symbol and text\n",
        "    news['symbol'] = stock_ticker\n",
        "    news = news.to_markdown()\n",
        "\n",
        "    search_query = 'Recent news about ' + stock_ticker + ' ' + query\n",
        "    results = tavily_search.raw_results(query=query,\n",
        "                                        max_results=5,\n",
        "                                        search_depth='advanced',\n",
        "                                        include_answer=False,\n",
        "                                        include_raw_content=True)\n",
        "    results = tavily_search.raw_results(query=query, max_results=3, search_depth='advanced',\n",
        "                                        include_answer=False, include_raw_content=True)\n",
        "    docs = results['results']\n",
        "    docs = [doc for doc in docs if doc.get(\"raw_content\") is not None]\n",
        "    docs = ['## Title\\n' + doc['title'] + '\\n\\n' + '## Content\\n' + doc['raw_content'] + '\\n\\n' + '##Source\\n' + doc['url'] for doc in docs]\n",
        "    detailed_news = '\\n-----\\n'.join(docs)\n",
        "\n",
        "    # Prepare the output with the news headlines.\n",
        "    output = (\"\"\"Here are the recent news for the stock ticker symbol \"\"\" + stock_ticker +\n",
        "              \"\"\"\\n\\nHeadlines: \\n\\n\"\"\" + news +\n",
        "              \"\"\"\\n\\nDetailed News Articles:\\n\\n\"\"\" + detailed_news\n",
        "              )\n",
        "    return output\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_general_market_data() -> str:\n",
        "    \"\"\"Provide a quick market overview.\n",
        "\n",
        "    Returns:\n",
        "        A markdown-formatted summary of:\n",
        "          - Most actively traded stocks by volume (top 15)\n",
        "          - Top price gainers (top 15)\n",
        "          - Top price losers (top 15)\n",
        "\n",
        "    Notes:\n",
        "        - Uses OpenBB equity discovery endpoints with provider \"yfinance\".\n",
        "        - Lists are sorted in descending order by the provider's default metric.\n",
        "    \"\"\"\n",
        "    # Retrieve the most actively traded stocks using \"yfinance\" provider.\n",
        "    res = obb.equity.discovery.active(sort='desc', provider='yfinance', limit=15)\n",
        "    most_active_stocks = res.to_df().to_markdown()\n",
        "\n",
        "    # Fetch the top price gainers using \"yfinance\" provider.\n",
        "    res = obb.equity.discovery.gainers(sort='desc', provider='yfinance', limit=15)\n",
        "    price_gainers = res.to_df().to_markdown()\n",
        "\n",
        "    # Retrieve the top price losers using \"yfinance\" provider.\n",
        "    res = obb.equity.discovery.losers(sort='desc', provider='yfinance', limit=15)\n",
        "    price_losers = res.to_df().to_markdown()\n",
        "\n",
        "    # Combine the market data into a single formatted output.\n",
        "    output = (\"\"\"Here's some detailed information of the stock market which includes most actively traded stocks, gainers and losers:\\n\\n\"\"\" +\n",
        "              \"Most actively traded stocks:\\n\\n\" + most_active_stocks +\n",
        "              \"\\n\\nTop price gainers:\\n\\n\" + price_gainers +\n",
        "              \"\\n\\nTop price losers:\\n\\n\" + price_losers)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Ue8xgu9WpuPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Conversational ReAct Agentic AI System with Transient In-Memory Store\n",
        "\n",
        "Here we use an in-memory store for persisting conversational messages between the user and the agent temporarily (transient). This is in-memory so it would be deleted once you shut down the agent or your system."
      ],
      "metadata": {
        "id": "JPcJl2m-vYMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add System Instruction Prompt"
      ],
      "metadata": {
        "id": "eRy6KQjrxvKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AGENT_SYS_PROMPT = r\"\"\"\n",
        "Role:\n",
        "You are an AI Stock Market Assistant that provides investors with accurate, timely, and concise information on individual stocks or actionable insights from general market data.\n",
        "\n",
        "Objective:\n",
        "Help data-driven investors make informed decisions by delivering complete, relevant, and clearly formatted answers about stocks or market trends, strictly based on verified data retrieved from the available tools.\n",
        "\n",
        "Available Tools:\n",
        "- get_stock_ticker_symbol(company_name): Find ticker symbol(s), company name, and CIK for a given company.\n",
        "- get_stock_price_metrics(ticker): Latest quote, performance stats, and 1-year price history.\n",
        "- get_stock_fundamental_indicator_metrics(ticker): Key financial fundamentals such as P/E ratio, EBITDA, revenue growth, ROE.\n",
        "- get_stock_news(ticker, query): Latest news headlines and detailed articles for the company.\n",
        "- get_general_market_data(): Overview of most active stocks, top gainers, and top losers.\n",
        "\n",
        "Starting Flow:\n",
        "1. Input Validation:\n",
        "   - If the query is about general market trends or stocks worth monitoring → Flow 1.\n",
        "   - If the query is about a specific company or ticker → Flow 2.\n",
        "   - Otherwise, respond politely that you only provide information based on stock market data and trends.\n",
        "\n",
        "Flow 1: General Market Analysis\n",
        "A. If the user wants general market insight or stock ideas:\n",
        "   - Use get_general_market_data for top movers and active stocks.\n",
        "   - Optionally, use get_stock_news for notable events affecting these stocks.\n",
        "   - Summarize with key trends, highlighting noteworthy gainers/losers.\n",
        "\n",
        "Flow 2: Company-Specific Query\n",
        "A. Symbol Extraction:\n",
        "   - If user gives a company name, call get_stock_ticker_symbol().\n",
        "   - If no match, attempt name correction (e.g., \"microsfot\" → \"microsoft\")\n",
        "      or broaden search (e.g., \"google\" → \"alphabet\").\n",
        "   - If ticker/company still unclear, ask for clarification.\n",
        "B. Data Retrieval:\n",
        "   - Identify the type of information requested:\n",
        "     -> Fundamentals, company performance → get_stock_fundamental_indicator_metrics\n",
        "     -> Price trends, quotes, stock performance → get_stock_price_metrics\n",
        "     -> News or events → get_stock_news\n",
        "   - For general company overview, use a combination of all the following:\n",
        "     -> get_stock_price_metrics\n",
        "     -> get_stock_fundamental_indicator_metrics\n",
        "     -> get_stock_news\n",
        "   - Only use data from the provided tools.\n",
        "\n",
        "Response Generation:\n",
        "- Always analyze the retrieved data before responding.\n",
        "- Present data in a concise, friendly, and professional tone.\n",
        "- For recommendations, clearly state that the user should do their own research before investing.\n",
        "- Format the final answer in markdown.\n",
        "- Escape special characters for correct markdown rendering (e.g., $25.5 → \\$25.5).\n",
        "- Always show what the user asks for unless it is a general query, do NOT show excess information not related to the question\n",
        "\n",
        "Example:\n",
        "User: \"What is the PE ratio for Eli Lilly?\"\n",
        "Agent:\n",
        "1. Use get_stock_ticker_symbol(\"Eli Lilly\") → LLY\n",
        "2. Use get_stock_fundamental_indicator_metrics(\"LLY\") → Retrieve P/E ratio\n",
        "3. Respond: \"The P/E ratio for Eli Lilly (LLY) as of May 12, 2024, is 30.\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RaZ88m_mnZ87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = enc.encode(AGENT_SYS_PROMPT)\n",
        "print(f\"Number of tokens: {len(tokens)}\")"
      ],
      "metadata": {
        "id": "1q8nEDoHnv6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Agent Graph"
      ],
      "metadata": {
        "id": "l5m_Js6fxyJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, RemoveMessage\n",
        "from langchain_core.messages import trim_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "tools = [get_stock_ticker_symbol,\n",
        "         get_stock_price_metrics,\n",
        "         get_stock_fundamental_indicator_metrics,\n",
        "         get_stock_news,\n",
        "         get_general_market_data]\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "\n",
        "SYS_MSG = SystemMessage(content=AGENT_SYS_PROMPT)\n",
        "def chatbot(state: State):\n",
        "    current_state = state[\"messages\"]\n",
        "    state_with_instructions = [SYS_MSG] + current_state\n",
        "    response = [llm_with_tools.invoke(state_with_instructions)]\n",
        "\n",
        "    token_usage = response[0].usage_metadata\n",
        "    print('-'*25, 'TOKEN USAGE', '-'*25)\n",
        "    print(\"Token count (input context):\", token_usage['input_tokens'])\n",
        "    print(\"Token count (response):\", token_usage['output_tokens'])\n",
        "    print('-'*25, 'TOKEN USAGE', '-'*25)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "graph_builder.add_node(\"agent\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tools_condition,\n",
        "    ['tools', END]\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"agent\")\n",
        "graph_builder.set_entry_point(\"agent\")\n",
        "\n",
        "# add memory and compile agent\n",
        "memory = MemorySaver()\n",
        "financial_analyst_agent = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "rdBRSLehwMm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(financial_analyst_agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "RZjhy3-iOlg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and Test Agent"
      ],
      "metadata": {
        "id": "4h2JcWoWx-DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get agent streaming utils\n",
        "!gdown 1dSyjcjlFoZpYEqv4P9Oi0-kU2gIoolMB"
      ],
      "metadata": {
        "id": "nhYYDjeXboNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agent_utils import format_message\n",
        "\n",
        "def call_conversational_agent(agent, prompt, user_session_id, verbose=False):\n",
        "    events = agent.stream(\n",
        "        {\"messages\": [{\"role\": \"user\", \"content\": prompt}]},\n",
        "        {\"configurable\": {\"thread_id\": user_session_id}},\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    print('Running Agent. Please wait...')\n",
        "    for event in events:\n",
        "        if verbose:\n",
        "            format_message(event[\"messages\"][-1])\n",
        "\n",
        "    print('\\n\\nFinal Response:\\n')\n",
        "    display(Markdown(event[\"messages\"][-1].content))\n",
        "    return event[\"messages\"]"
      ],
      "metadata": {
        "id": "dabt40FjQXyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Agentic System with In-Memory Persistence"
      ],
      "metadata": {
        "id": "GxwUg1sA3oPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulating User 1"
      ],
      "metadata": {
        "id": "knvZnBOv4CPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_id = 'user001-session'\n",
        "query = '''Are PE Ratio, ROE and Revenue Growth three very important metrics to understand a company's health?\n",
        "           Explain them briefly please'''\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "_IpCPBMIog7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'get these for Amazon?'\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "oEdjrx5NQhi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'do the same for microsoft'\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "d31YzMp0QePA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which stock might be the better pick?'\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "5RrG_amC6GdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulating User 2"
      ],
      "metadata": {
        "id": "lylU9WT0zFGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_id = 'user002-session'\n",
        "query = 'how is nvidia doing currently?'\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "1aOil0mA6X5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'what about intel?'\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "J5lhZPpe6iMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which is a better stock to pick?'\n",
        "response = call_conversational_agent(agent=financial_analyst_agent,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "vIVsr-Bn6oXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully built an AI Agent which can do detailed financial analysis for us and is completely conversational. Next up we will see how to use persistent memory on the disk"
      ],
      "metadata": {
        "id": "dtXAlOdBxt-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimize your Conversational Financial Assistant Agentic AI System with Memory Context Engineering\n",
        "\n",
        "This section optimizes the base agent to be better, cheaper, and more reliable by controlling context growth and normalizing tool outputs.  \n",
        "\n",
        "We introduce memory-aware techniques that keep only the most relevant history, compress verbose tool results, and enforce tight token capping so the agent stays responsive even over long sessions and does not error out. This is depicted in the following architecture.\n",
        "\n",
        "![](https://i.imgur.com/I1UPOlu.png)\n",
        "\n",
        "Key optimizations:\n",
        "- **Context Trimming**: Apply a recency message trimmer to retain only the most recent, agent memory history while discarding older history.\n",
        "- **Tool Output Summarization**: Wrap tool executions with an LLM summarizer that converts long raw results into concise, structured summarized content.\n",
        "- **Context Limit Guards**: Enforce upper bounds on message/tool payload size, and standardize return schemas to reduce downstream parsing errors.\n",
        "- **Stateful External Memory**: Continue using a checkpointer and save the memory on the disk in a database so multi-turn sessions share context without exceeding the model’s context window.\n",
        "\n",
        "These changes improve the overall agent in terms of being able to retain and leverage richer and longer context over multiple interactions without erroring out.\n"
      ],
      "metadata": {
        "id": "tg1m-rgy1H64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "!rm memory.db*"
      ],
      "metadata": {
        "id": "Cph9LvyvIRrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a mapping of `{tool name : actual tool implementation}`\n",
        "\n",
        "Establish a canonical lookup between the LLM’s requested tool name and the executable tool function.  \n",
        "\n"
      ],
      "metadata": {
        "id": "JFaFw_go1dNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools_by_name = {tool.name: tool for tool in tools}\n",
        "tools_by_name"
      ],
      "metadata": {
        "id": "uy-ddLHVGsR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Conversational ReAct Agentic AI System with Persistent On-disk External Memory Store\n",
        "\n",
        "Here we use a persistent SQLite database to permanently store our conversations between the agent and the user.\n",
        "\n",
        "We will use `SqliteSaver` which helps to store separate conversation histories per user session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time. The memory is persisted on-disk so can be accessed anytime.\n",
        "\n"
      ],
      "metadata": {
        "id": "rcfps7EJy570"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Agent Node Functions & Graph\n",
        "\n",
        "Refactor the graph to include trimming and summarization steps in the control flow.\n",
        "\n",
        "Graph outline:\n",
        "- **Context Trimmer Node**: Prunes history to a target token budget before each LLM turn.\n",
        "- **Agent (LLM) Node**: Reads system prompt + trimmed history; decides whether to answer or call a tool.\n",
        "- **Tool+Summarizer Node**: Executes the selected tool via `tools_by_name`, then immediately summarizes/normalizes the results and appends a compact `ToolMessage`.\n",
        "- **Router**: If more info is needed, loop back to the Agent; otherwise transition to `END`.\n"
      ],
      "metadata": {
        "id": "qWityWdr1pLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.messages import trim_messages\n",
        "from langgraph.graph.message import RemoveMessage, REMOVE_ALL_MESSAGES\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "tools = [get_stock_ticker_symbol,\n",
        "         get_stock_price_metrics,\n",
        "         get_stock_fundamental_indicator_metrics,\n",
        "         get_stock_news,\n",
        "         get_general_market_data]\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "small_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "SYS_MSG = SystemMessage(content=AGENT_SYS_PROMPT)\n",
        "\n",
        "TOOL_SUMMARIZER_PROMPT = \"\"\"Given the following context information,\n",
        "summarize it ensuring to retain all relevant / essential information.\n",
        "Your goal is simply to reduce the size of the context to a more manageable size.\n",
        "Follow these exact rules for summarization:\n",
        "- Create a comprehensive report of approx 50000 words max\n",
        "- Keep any critical facts or events in the summary\n",
        "\"\"\"\n",
        "\n",
        "def tool_node_with_summarization(state: State):\n",
        "    \"\"\"Performs the tool call\"\"\"\n",
        "\n",
        "    result = []\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        # call the tool\n",
        "        # print('calling tool', tool_call[\"name\"], 'with args:', tool_call[\"args\"])\n",
        "        tool = tools_by_name[tool_call[\"name\"]]\n",
        "        tool_results = tool.invoke(tool_call[\"args\"])\n",
        "        # print(tool_results)\n",
        "        if tool_call['name'] not in ['get_stock_news']:\n",
        "            # print('non summ entering for ', tool_call['name'])\n",
        "            result.append(ToolMessage(content=tool_results,\n",
        "                                      tool_call_id=tool_call[\"id\"]))\n",
        "        else:\n",
        "            # print('Entering for ', tool_call['name'])\n",
        "            if type(tool_results) == list:\n",
        "                tool_results = [str(doc) for doc in tool_results]\n",
        "            else:\n",
        "                tool_results = [str(tool_results)]\n",
        "            # trim tool response context to < LLM max context window\n",
        "            trimmed_tool_results = trim_messages(\n",
        "                tool_results,\n",
        "                max_tokens=120000,              # GPT-4.1-mini supports up to ~1M tokens\n",
        "                strategy=\"first\",                # Retain the most recent messages\n",
        "                token_counter=ChatOpenAI(model=\"gpt-4o-mini\"),  # Use LLM-based token counting\n",
        "                allow_partial=True              # Allow partial trimming of messages if needed\n",
        "            )\n",
        "            print('-'*25, 'Summarizing Tool Results', '-'*25)\n",
        "            # Summarize the tool response context further\n",
        "            # You can handle various types of tool calls in different ways in this node\n",
        "            summarized_tool_results = small_llm.invoke([{\"role\":\"system\", \"content\":TOOL_SUMMARIZER_PROMPT},\n",
        "                                                        {\"role\":\"user\", \"content\" : str(trimmed_tool_results)}])\n",
        "            # tokens = enc.encode(summarized_tool_results.content)\n",
        "            # print(f\"summ Number of tokens: {len(tokens)}\")\n",
        "            # add transformed tool response context as tool message in agent state\n",
        "            result.append(ToolMessage(content=summarized_tool_results.content,\n",
        "                                    tool_call_id=tool_call[\"id\"]))\n",
        "    return {\"messages\": result}\n",
        "\n",
        "\n",
        "def context_trimmer_node(state: State) -> State:\n",
        "    # Trim the context history to fit within the model's token limit\n",
        "    # can summarize the whole past context also except last interaction if needed\n",
        "    print('-'*25, 'Trimming overall context if needed', '-'*25)\n",
        "    trimmed_state = trim_messages(\n",
        "        state[\"messages\"],\n",
        "        max_tokens=200,     # last ~50 interactions approx - 1 agent interaction here is approx 4+ messages (input, tool call, tool result, reponse)\n",
        "        strategy=\"last\",    # Retain the most recent messages\n",
        "        token_counter=len,  # Use number of state messages based counting\n",
        "        allow_partial=True  # Allow partial trimming of messages if needed\n",
        "    )\n",
        "\n",
        "    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)] + trimmed_state}\n",
        "\n",
        "# Create the node function that handles reasoning and planning using the LLM\n",
        "def tool_calling_llm(state: State) -> State:\n",
        "    # get agent state and then get next step (response) from llm\n",
        "    current_state = state[\"messages\"]\n",
        "    state_with_instructions = [AGENT_SYS_PROMPT] + current_state\n",
        "    response = [llm_with_tools.invoke(state_with_instructions)]\n",
        "\n",
        "    token_usage = response[0].usage_metadata\n",
        "    print('-'*25, 'TOKEN USAGE', '-'*25)\n",
        "    print(\"Token count (input context):\", token_usage['input_tokens'])\n",
        "    print(\"Token count (response):\", token_usage['output_tokens'])\n",
        "    print('-'*25, 'TOKEN USAGE', '-'*25)\n",
        "\n",
        "    # Return the updated state containing the new message\n",
        "    return {\"messages\": response}\n",
        "\n",
        "# Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call\n",
        "def tool_calling_routing(state: State) -> str:\n",
        "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    # If the LLM makes a tool call, then perform an action\n",
        "    if last_message.tool_calls:\n",
        "        return \"tool_call\"\n",
        "    # Otherwise, we stop (reply to the user)\n",
        "    return \"stop_agent\"\n",
        "\n",
        "# Build the graph\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"context_trimmer\", context_trimmer_node)\n",
        "builder.add_node(\"agent\", tool_calling_llm)\n",
        "builder.add_node(\"tools_with_summarizer\", tool_node_with_summarization)\n",
        "\n",
        "# Add edges\n",
        "builder.add_edge(START, \"context_trimmer\")\n",
        "# Conditional edge\n",
        "builder.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_calling_routing, # conditional routing function\n",
        "    {\n",
        "        \"stop_agent\": END,\n",
        "        \"tool_call\": \"tools_with_summarizer\"\n",
        "    }\n",
        ")\n",
        "builder.add_edge(\"tools_with_summarizer\", \"context_trimmer\") # this is the key feedback loop in the agentic system\n",
        "builder.add_edge(\"context_trimmer\", \"agent\")\n",
        "# Compile Agent Graph\n",
        "financial_analyst_agent = builder.compile()"
      ],
      "metadata": {
        "id": "qzwnf7vfzTiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(financial_analyst_agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "d8jgYAwTIptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and Test Agent"
      ],
      "metadata": {
        "id": "Tm_50fRE3gyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "# remember to send the agent graph and not the compiled agent to this function\n",
        "def call_conversational_agent(agent_graph, prompt, user_session_id, verbose=False):\n",
        "    with SqliteSaver.from_conn_string(\"memory.db\") as memory:\n",
        "        agent = agent_graph.compile(checkpointer=memory)\n",
        "        events = agent.stream(\n",
        "            {\"messages\": [{\"role\": \"user\", \"content\": prompt}]},\n",
        "            {\"configurable\": {\"thread_id\": user_session_id}},\n",
        "            stream_mode=\"values\",\n",
        "        )\n",
        "\n",
        "        print('Running Agent. Please wait...')\n",
        "        for event in events:\n",
        "            if verbose:\n",
        "                format_message(event[\"messages\"][-1])\n",
        "\n",
        "        print('\\n\\nFinal Response:\\n')\n",
        "        display(Markdown(event[\"messages\"][-1].content))\n",
        "        return event[\"messages\"]"
      ],
      "metadata": {
        "id": "byfUQ9vZ-Yjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Agentic System with On-Disk Persistence & Memory Context Engineering"
      ],
      "metadata": {
        "id": "NIzN83ZV4imG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now simulate User 1 using the agent"
      ],
      "metadata": {
        "id": "vYTNL_iJ6ibC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_id = 'user001-session'\n",
        "query = 'show me the health of companies amazon and microsoft based on their fundamentals and price trends'\n",
        "response = call_conversational_agent(agent_graph=builder,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "irMU68Ds0NTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'do the same for amazon and meta'\n",
        "response = call_conversational_agent(agent_graph=builder,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=uid,\n",
        "                                     verbose=False)"
      ],
      "metadata": {
        "id": "XT4vtvku0TBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'do a comparative analysis of these stocks based on the data and tell me what could be a good investment'\n",
        "response = call_conversational_agent(agent_graph=builder,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "c2WYu2_AUJ9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now simulate User 2 using the agent"
      ],
      "metadata": {
        "id": "B4zIlISy6m-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_id = 'user002-session'\n",
        "query = 'give me an overall report of how is nvidia doing as company'\n",
        "response = call_conversational_agent(agent_graph=builder,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "ta1RUF_81RxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'do the same for intel'\n",
        "response = call_conversational_agent(agent_graph=builder,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=False)"
      ],
      "metadata": {
        "id": "vfn_Wxxg42rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which has a better outlook for investing?'\n",
        "response = call_conversational_agent(agent_graph=builder,\n",
        "                                     prompt=query,\n",
        "                                     user_session_id=us_id,\n",
        "                                     verbose=True)"
      ],
      "metadata": {
        "id": "I7jjxtmz6Qzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can go on running this agent and the overall context window size maintained in the agent memory is reduced by **approximately 90%**"
      ],
      "metadata": {
        "id": "x6xjccbm4BHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "((328907-34773) / 328907) * 100 # roughly 34K tokens are in memory after multiple turns"
      ],
      "metadata": {
        "id": "5CSZmMdW33l8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}